import numpy as np
import tensorflow as tf
import os

# ëª¨ë¸ ë¡œë“œ
model = tf.keras.models.load_model("./model/Sign_ED_best.keras")

# ì €ì¥ëœ ë°ì´í„° ê²½ë¡œ
dataset_path = "./Sign_ED/test/testdata"

# ì œìŠ¤ì²˜ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ (ì˜¤ë¥˜ í•´ê²°)
actions = ['ã„±', 'ã„²', 'ã„´', 'ã„·', 'ã„¸', 'ã„¹', 'ã…', 'ã…‚', 'ã…ƒ', 'ã……', 'ã…†', 'ã…‡', 'ã…ˆ', 'ã…‰', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…',
           'ã…', 'ã…‘', 'ã…“', 'ã…•', 'ã…—', 'ã…›', 'ã…œ', 'ã… ', 'ã…¡', 'ã…£', 'ã…', 'ã…’', 'ã…”', 'ã…–', 'ã…¢', 'ã…š', 'ã…Ÿ',
           'ã…˜', 'ã…™', 'ã…', 'ã…']

# ìŒììŒ/ì´ì¤‘ëª¨ìŒ ê·œì¹™
double_consonants = {'ã„²': ['ã„±', 'ã„±'], 'ã„¸': ['ã„·', 'ã„·'], 'ã…ƒ': ['ã…‚', 'ã…‚'], 'ã…†': ['ã……', 'ã……'], 'ã…‰': ['ã…ˆ', 'ã…ˆ']}
double_vowels = {'ã…˜': ['ã…—', 'ã…'], 'ã…™': ['ã…—', 'ã…'], 'ã…': ['ã…œ', 'ã…“'], 'ã…': ['ã…œ', 'ã…”']}

# ì €ì¥ëœ ë°ì´í„° íŒŒì¼ í™•ì¸
files = [f for f in os.listdir(dataset_path) if f.startswith("test_landmarks_")]
for file in files:
    label = file.replace("test_landmarks_", "").replace(".npy", "")  # ë¼ë²¨ ì¶”ì¶œ
    test_data = np.load(os.path.join(dataset_path, file))  # ì €ì¥ëœ ë°ì´í„° ë¡œë“œ
    test_data = np.expand_dims(test_data, axis=0)  # ëª¨ë¸ ì…ë ¥ í¬ê¸° ë§ì¶”ê¸°

    # ëª¨ë¸ ì˜ˆì¸¡
    predictions = model.predict(test_data)[0]
    max_index = np.argmax(predictions)
    predicted_label = actions[max_index]  # ğŸ”¥ ì˜¤ë¥˜ í•´ê²°ë¨!
    confidence = predictions[max_index] * 100

    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ“Œ ì €ì¥ëœ ë°ì´í„° ë¼ë²¨: {label}")
    print(f"âœ… ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: {predicted_label} ({confidence:.2f}%)")

    # ìŒììŒ/ì´ì¤‘ëª¨ìŒ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸
    if label in double_consonants or label in double_vowels:
        print(f"âš ï¸ {label}ì€ ìŒììŒ/ì´ì¤‘ëª¨ìŒì…ë‹ˆë‹¤!")
        if label in double_consonants:
            components = double_consonants[label]
        elif label in double_vowels:
            components = double_vowels[label]

        print(f"êµ¬ì„± ìš”ì†Œ: {components}")
        # ê° êµ¬ì„± ìš”ì†Œì˜ ì˜ˆì¸¡ í™•ì¸ (ë””ë²„ê¹…ìš©)
        for i, component in enumerate(components):
            component_data = np.load(os.path.join(dataset_path, f"test_landmarks_{component}.npy"))
            component_data = np.expand_dims(component_data, axis=0)
            component_predictions = model.predict(component_data)[0]
            component_max_index = np.argmax(component_predictions)
            component_label = actions[component_max_index]
            component_confidence = component_predictions[component_max_index] * 100
            print(f"  ğŸ”¹ {i+1}ë²ˆì§¸ ì œìŠ¤ì²˜ {component} â†’ ì˜ˆì¸¡: {component_label} ({component_confidence:.2f}%)")

    print("-" * 50)
